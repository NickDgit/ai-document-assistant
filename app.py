import streamlit as st
import os
from dotenv import load_dotenv
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from PyPDF2 import PdfReader

# Î¦ÏŒÏÏ„Ï‰ÏƒÎ· ÏÏ…Î¸Î¼Î¯ÏƒÎµÏ‰Î½
load_dotenv()

# Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Î£ÎµÎ»Î¯Î´Î±Ï‚
st.set_page_config(page_title="AI Smart Summarizer", page_icon="ğŸ¤–", layout="wide")

# --- SIDEBAR (ÎŒÏ€Ï‰Ï‚ ÏƒÏ„Î·Î½ ÎµÎ¹ÎºÏŒÎ½Î± ÏƒÎ¿Ï…) ---
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/2811/2811194.png", width=100)
    st.title("Î¡Ï…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚")
    option = st.radio("Î•Ï€Î¯Î»ÎµÎ¾Îµ Ï€Î·Î³Î®:", ("PDF Î‘ÏÏ‡ÎµÎ¯Î¿", "ÎšÎµÎ¯Î¼ÎµÎ½Î¿ (Copy-Paste)"))

    st.divider()
    summary_type = st.select_slider(
        "Î›ÎµÏ€Ï„Î¿Î¼Î­ÏÎµÎ¹Î± Î ÎµÏÎ¯Î»Î·ÏˆÎ·Ï‚:",
        options=["Î£ÏÎ½Ï„Î¿Î¼Î·", "ÎšÎ±Î½Î¿Î½Î¹ÎºÎ®", "Î‘Î½Î±Î»Ï…Ï„Î¹ÎºÎ®"]
    )
    st.info("Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ Llama 3.1 Î¼Î­ÏƒÏ‰ Groq API.")

# --- ÎšÎ¥Î¡Î™ÎŸ ÎœÎ•Î¡ÎŸÎ£ ---
st.title("ğŸ¤– AI Smart Assistant")
st.markdown(f"### Î‘Î½Î¬Î»Ï…ÏƒÎ· Î±Ï€ÏŒ: **{option}**")

# Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Ï„Î¿Ï… AI
llm = ChatGroq(model_name="llama-3.1-8b-instant", temperature=0)


def ai_call(text, system_prompt, user_input):
    """Î“ÎµÎ½Î¹ÎºÎ® ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· Î³Î¹Î± ÎºÎ»Î®ÏƒÎ· ÏƒÏ„Î¿ AI"""
    limited_text = text[:15000]
    prompt = ChatPromptTemplate.from_template(system_prompt)
    chain = prompt | llm
    return chain.invoke({"context": limited_text, "question": user_input}).content


# --- Î•ÎÎ‘Î“Î©Î“Î— ÎšÎ•Î™ÎœÎ•ÎÎŸÎ¥ ---
document_text = ""

if option == "PDF Î‘ÏÏ‡ÎµÎ¯Î¿":
    uploaded_file = st.file_uploader("Î‘Î½Î­Î²Î±ÏƒÎµ Ï„Î¿ PDF ÏƒÎ¿Ï…", type="pdf")
    if uploaded_file:
        pdf_reader = PdfReader(uploaded_file)
        document_text = " ".join([page.extract_text() for page in pdf_reader.pages if page.extract_text()])
        st.success("Î¤Î¿ Î­Î³Î³ÏÎ±Ï†Î¿ Ï†Î¿ÏÏ„ÏÎ¸Î·ÎºÎµ!")

elif option == "ÎšÎµÎ¯Î¼ÎµÎ½Î¿ (Copy-Paste)":
    document_text = st.text_area("Î•Ï€Î¹ÎºÏŒÎ»Î»Î·ÏƒÎµ Ï„Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ ÎµÎ´Ï:", height=200)

# --- Î›Î•Î™Î¤ÎŸÎ¥Î¡Î“Î™Î•Î£ (ÎœÏŒÎ½Î¿ Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ ÎºÎµÎ¯Î¼ÎµÎ½Î¿) ---
if document_text:
    col1, col2 = st.columns([1, 1])  # Î§Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÏƒÎµ Î´ÏÎ¿ ÏƒÏ„Î®Î»ÎµÏ‚ Î³Î¹Î± Î ÎµÏÎ¯Î»Î·ÏˆÎ· ÎºÎ±Î¹ Chat

    with col1:
        st.subheader("ğŸ“ Î ÎµÏÎ¯Î»Î·ÏˆÎ·")
        if st.button("ğŸš€ Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î ÎµÏÎ¯Î»Î·ÏˆÎ·Ï‚"):
            with st.spinner("Î‘Î½Î±Î»ÏÏ‰..."):
                sys_p = f"ÎšÎ¬Î½Îµ Î¼Î¹Î± {summary_type} Ï€ÎµÏÎ¯Î»Î·ÏˆÎ· ÏƒÏ„Î± Î•Î»Î»Î·Î½Î¹ÎºÎ¬ Î¼Îµ bullet points Î³Î¹Î± Ï„Î¿ Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ ÎºÎµÎ¯Î¼ÎµÎ½Î¿:\n\n{{context}}"
                summary = ai_call(document_text, sys_p, "")
                st.markdown(summary)
                st.download_button("ğŸ“¥ Î›Î®ÏˆÎ· Î ÎµÏÎ¯Î»Î·ÏˆÎ·Ï‚", summary, file_name="summary.txt")

    with col2:
        st.subheader("ğŸ’¬ Chat Î¼Îµ Ï„Î¿ ÎˆÎ³Î³ÏÎ±Ï†Î¿")
        user_question = st.text_input("ÎšÎ¬Î½Îµ Î¼Î¹Î± ÎµÏÏÏ„Î·ÏƒÎ·:")
        if user_question:
            with st.spinner("Î£ÎºÎ­Ï†Ï„Î¿Î¼Î±Î¹..."):
                sys_p = """
                Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ Ï„Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Î³Î¹Î± Î½Î± Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚ ÏƒÏ„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ·. 
                Î‘Ï€Î¬Î½Ï„Î·ÏƒÎµ Î¼ÏŒÎ½Î¿ Î²Î¬ÏƒÎµÎ¹ Ï„Î¿Ï… ÎºÎµÎ¹Î¼Î­Î½Î¿Ï….
                Context: {context}
                Î•ÏÏÏ„Î·ÏƒÎ·: {question}
                """
                answer = ai_call(document_text, sys_p, user_question)
                st.info(answer)

else:
    st.info("Î Î±ÏÎ±ÎºÎ±Î»Ï Î±Î½Î­Î²Î±ÏƒÎµ Î­Î½Î± Î±ÏÏ‡ÎµÎ¯Î¿ Î® Î²Î¬Î»Îµ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Î³Î¹Î± Î½Î± Î¾ÎµÎºÎ¹Î½Î®ÏƒÎµÎ¹Ï‚.")